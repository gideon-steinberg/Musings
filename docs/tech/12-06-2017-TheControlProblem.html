<!DOCTYPE html>
<html lang="en">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <head>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <title> Gideon's Musings - The Control Problem </title>
  </head>
  <body>
    <ol class="breadcrumb">
      <li><a href="/Musings/">Home</a></li>
      <li><a href="/Musings/tech.html">Technology</a></li>
      <li><a href="#">Maths</a></li>
      <li><a href="/Musings/society.html">Society</a></li>
    </ol>
    <div class="container-fluid">
      <h1> The Control Problem </h1>
      So let's start with something really complicated. The control problem in Artifical intelligence.
      </br>
      If you are not aware of the control problem here is a super simple breakdown of it:
      </br> </br>
      We are currently working on an artifical general intelligence. Once we create one it will probably very quickly become and artifical super intelligence (ASI). This means it is smarter than all mankind. This is a problem.
      </br>
      Artificial intelligence programs are most likely going to be optimisation machines. What it is trying to optimise is run against its "value function". This tells it how "good" that action is. Let's say you create a program that wants to optimise the amount of cute animal pictures, ie more cute animals pictures rates high on its value function. It really doesn't matter what it is but I am sticking with animal pictures :)
      </br></br>
      What happens when this machine is super intelligent and it "optimises" the entire world to be cute animal pictures. Remember that is the only thing it cares about. Good job humanity you just created a world with ONLY cute animal pictures.
      </br>
      The control problem is simple: How do we control a super intelligent artifical intelligence so that it doesn't "do things we don't want it to do".
      </br>
      <strong>NOTE - We get exactly one shot at this. Once a ASI is created and has access to the internet, that is it. Game over.</strong>
      </br></br>
      Ok, now that we are all on the same page, what can we do?
      </br>
      It turns out, not very much. There are so many things where stuff just goes straight up wrong.
      </br>
      Let's examine how we are all screwed shall we!
      <h2> The Off Button Conundrum </h2>
      Let's say you build your ASI with an off button. Great! If it starts doing things we don't like, let's push the off button. Will the AI allow you to push the button? There is good chance that pushing the button (ie being turned off) score very poorly on the AI's value function. So it will probably stop you from pushing it.
      </br></br>
      Clap clap, ok let's try and fix that "slight" issue. Uh... let's make pushing the button score highly on the value function. Your AI starts, examines the world. Aaaaaand turns itself off.
      </br>
      <img src="/Musings/pics/facepalm.jpg" alt="Facepalm" height="300" width="300" />
      </br>
      Ok, so the AI can not turn itself off. Good that'll solve it!
      </br>
      But now, if it knows that you can turn it off, it's goal (the best possible outcome) is to get <strong>YOU</strong> to turn it off.
      </br>
      God damnit! This is hard.
      </br></br>
      Keep in mind this is a <strong>BINARY</strong> off button. We have not talked about a complex system which will have way harder challenges!
      <h2> The Clone Creation Issue </h2>
      Ok we can do this, let's make the AI not care about the button!
      </br>
      Can the AI make clones and improve itself? If so, why would it copy this part of its value function that "does nothing". It will just optimise it away.
      </br>
      Great, there goes all the safety you were working on.
      <h2> The Internet Connection Issue </h2>
      Do you think you can outsmart an ASI?
      <br>
      Let's say you are put into a room with an ASI. Your one goal is to not connect the ASI to the internet and it's one goal is to connect to the internet. Would you win?
      </br></br>
      The ASI is a useful tool. We would not build it any other way. Let's say it knows about the internet somehow. We then go to ask it a question say "How do we cure cancer?".
      </br>
      The AI asks for more information (eg wikipedia) so it can figure out the answer. You lose!
      </br>
      Remember we are talking about a ASI here, it has more intelligence than the entire human race. Surely it can figure out "lying" or "pretending to be naive". It will be a hard battle. And what we lose here, is the entire human race.
      <h2> The Human Issue </h2>
      Let's say by some miracle you have created a safe ASI. No clue how you do so but you somehow manage this really hard task.
      </br>
      What happens if someone who has a "unpopular" opinion gets their hands on one. They can ask the "safe ASI" to do terrible evils.
      </br>
      Let's hope that some awesome, sane, uncorruptable scientists who just want to solve all the worlds problems creates it.
      </br></br>
      An ASI will be our <strong>LAST</strong> invention ever. Once we create it, it will invent ALL THE THINGS. Let's do it properly and safely so we don't all die.
      </br>
      I think that is enough for now, I will probably re-visit this area as there is <strong>SO</strong> much to say!
      </br>
      <img src="/Musings/pics/cat_on_blanket.jpg" alt="A cat on a bed" height="500" width="500" />
    </div>
  </body>
</html>